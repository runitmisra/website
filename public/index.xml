<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Runit Misra</title>
    <link>http://example.org/</link>
    <description>Recent content on Runit Misra</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="http://example.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building a Go CI pipeline in an offline environment</title>
      <link>http://example.org/posts/gocioffline/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/posts/gocioffline/</guid>
      <description>In today&amp;rsquo;s interconnected world, the majority of software development and deployment processes heavily rely on internet connectivity. However, certain organizations dealing with highly sensitive data cannot afford to expose their infrastructure to the internet or must tightly control internet access. This is where Offline environments, also known as Airgapped environments, come into play. Offline environments refer to infrastructure with limited or no connectivity to the open internet. While they offer enhanced security and independence from internet availability, they pose unique challenges for building CI (Continuous Integration) pipelines, especially when it comes to managing third-party dependencies.</description>
      <content>&lt;p&gt;In today&amp;rsquo;s interconnected world, the majority of software development and deployment processes heavily rely on internet connectivity. However, certain organizations dealing with highly sensitive data cannot afford to expose their infrastructure to the internet or must tightly control internet access. This is where Offline environments, also known as Airgapped environments, come into play. Offline environments refer to infrastructure with limited or no connectivity to the open internet. While they offer enhanced security and independence from internet availability, they pose unique challenges for building CI (Continuous Integration) pipelines, especially when it comes to managing third-party dependencies. In this blog post, I will share my experiences and insights on overcoming this challenge, exploring various solutions tailored to specific situations.&lt;/p&gt;
&lt;p&gt;The task at hand is straightforward: construct a CI pipeline that retrieves the latest code from the application&amp;rsquo;s repository, executes unit tests, and creates a Docker image for the application. However, building such a pipeline becomes challenging in an offline environment where accessing dependencies from external sources like GitHub or Go&amp;rsquo;s package registry is not feasible. These dependencies are required both during test runs and application builds. In the following sections, we will explore effective solutions to tackle this issue and ensure a successful CI pipeline in an offline environment.&lt;/p&gt;
&lt;h2 id=&#34;use-a-private-registry&#34;&gt;Use a private registry&lt;/h2&gt;
&lt;p&gt;This is by far the best solution and the one that almost anyone faced with this situation will opt for. Artifact repositories make life very simple for engineers looking for fine-grained control over their software supply chain, simplifying the management of organization-generated artifacts and enabling controlled retrieval of artifacts from the internet, ensuring they meet necessary security requirements.&lt;/p&gt;
&lt;p&gt;There are some excellent choices out there like JFrog&amp;rsquo;s Artifactory or Sonartype&amp;rsquo;s Nexus repository. You can use them as proxy to pull any required package from a list of verified sources which would be controlled by you. You can also upload packages manually to these repositories after through security scans and policy checks to make sure each package meets the security standards you have set. Once set up, private registries can be useful for multiple teams across the organization to store artifacts, track their versions and securely access them in an offline environment.&lt;/p&gt;
&lt;p&gt;More information available here:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Artifactory:&lt;/strong&gt; &lt;a href=&#34;https://jfrog.com/help/r/jfrog-artifactory-documentation/go-registry&#34;&gt;https://jfrog.com/help/r/jfrog-artifactory-documentation/go-registry&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nexus:&lt;/strong&gt; &lt;a href=&#34;https://help.sonatype.com/repomanager3/nexus-repository-administration/formats/go-repositories&#34;&gt;https://help.sonatype.com/repomanager3/nexus-repository-administration/formats/go-repositories&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;use-go-vendoring&#34;&gt;Use go vendoring&lt;/h2&gt;
&lt;p&gt;This might seem like a hack because it probably is. Vendoring, if you aren&amp;rsquo;t familiar, enables you to commit the dependencies next to the code. Vendoring is used to maintain the deterministic nature of go builds in an event a package your application depends on might get deleted/moved/broken later down the line.&lt;/p&gt;
&lt;p&gt;However, this works out great for us because when vendoring is enabled, go uses the packages it downloaded in the &lt;code&gt;vendor&lt;/code&gt; directory to satisfy the application dependencies. This download can be done on a machine with internet access like the developer&amp;rsquo;s PC using the &lt;code&gt;go mod vendor&lt;/code&gt; command. Once the &lt;code&gt;vendor&lt;/code&gt; directory is created, it can be committed alongside the code. The CI pipeline can then pull the dependencies directly from the &lt;code&gt;vendor&lt;/code&gt; directory because it is part of the code repository and hence there is no need for connecting to the internet.&lt;/p&gt;
&lt;p&gt;Now that vendoring is set up, use &lt;code&gt;-mod=vendor&lt;/code&gt; argument in all the build commands in the CI pipeline. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To test use &lt;code&gt;go test -mod=vendor ./...&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To build use &lt;code&gt;go build -mod=vendor cmd/main.go&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;use-a-base-image&#34;&gt;Use a base image&lt;/h2&gt;
&lt;p&gt;Here, by &amp;ldquo;Base image&amp;rdquo; I mean a docker image you prepare beforehand that has the necessary dependencies already downloaded and baked into it. Here the &lt;code&gt;go mod download&lt;/code&gt; command would come in handy. Just like vendoring, the dependencies can be downloaded from a machine with internet access but instead of maintaining the packages in the repository along side the code, the packages are downloaded in a docker image which is then used as the base for the final application docker image.&lt;/p&gt;
&lt;p&gt;Create the base image with a dockerfile looking something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Dockerfile&#34; data-lang=&#34;Dockerfile&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; golang:alpine&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;RUN&lt;/span&gt; go mod download -x&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can tag this something like &lt;code&gt;custom-base:latest&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Then the application Dockerfile will look something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Dockerfile&#34; data-lang=&#34;Dockerfile&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; custom-base:latest AS builder&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;COPY&lt;/span&gt; . /build&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;RUN&lt;/span&gt; go build -o /build/myapp&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; alpine:latest&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;COPY&lt;/span&gt; --from&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;builder /build/myapp /app&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CMD&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;./app/myapp&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To be honest, this is not the most optimal solution. The biggest overhead this will create for you is to re-build this image in case any dependency gets updated, added or removed. You could always automate this but it has to be done on a machine with internet access and you&amp;rsquo;d have to spend time writing logic when better alternatives are available.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Not being able to rely on the convenience of having internet connectivity can be a little frustrating in day-to-day operations. But convenience sometimes comes with a cost - in our case it is fine grained control over access to internet to maintain security and privacy standards. However, these methods can hopefully help you in overcoming the challenge of CI in offline environments.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>About</title>
      <link>http://example.org/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/about/</guid>
      <description>Hi there My name is Runit! welcome to my website.
I am a DevOps/SRE professional with 4 years of experience creating and maintaining scalable and reliable infrastructure.
I am currently working at InfraCloud Technologies. Here are some of the things I have worked on here:
Planning and creation of SaaS infrastructure on AWS as well as On-Prem DCs Infrastructure automation with Terraform Managing Kubernetes Clusters Creating CI pipelines with Github Actions Creating CD workflow based on GitOps using ArgoCD Setting up monitoring tools on Kubernetes Clusters like the PLG stack (Prometheus, Loki, Grafana), Elasticsearch with Kibana and Fluent-bit Prior to InfraCloud, I worked with Crest Data Systems.</description>
      <content>&lt;h1 id=&#34;hi-there&#34;&gt;Hi there&lt;/h1&gt;
&lt;p&gt;My name is Runit! welcome to my website.&lt;/p&gt;
&lt;p&gt;I am a DevOps/SRE professional with 4 years of experience creating and maintaining scalable and reliable infrastructure.&lt;/p&gt;
&lt;p&gt;I am currently working at InfraCloud Technologies. Here are some of the things I have worked on here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Planning and creation of SaaS infrastructure on AWS as well as On-Prem DCs&lt;/li&gt;
&lt;li&gt;Infrastructure automation with Terraform&lt;/li&gt;
&lt;li&gt;Managing Kubernetes Clusters&lt;/li&gt;
&lt;li&gt;Creating CI pipelines with Github Actions&lt;/li&gt;
&lt;li&gt;Creating CD workflow based on GitOps using ArgoCD&lt;/li&gt;
&lt;li&gt;Setting up monitoring tools on Kubernetes Clusters like the PLG stack (Prometheus, Loki, Grafana), Elasticsearch with Kibana and Fluent-bit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to InfraCloud, I worked with Crest Data Systems. At CDS, I worked on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Customer stack management for Splunk Cloud in AWS&lt;/li&gt;
&lt;li&gt;Infrastructure changes with Terraform and Jenkins&lt;/li&gt;
&lt;li&gt;Config management using Puppet&lt;/li&gt;
&lt;li&gt;Technical support for Splunk app and add-on installations&lt;/li&gt;
&lt;li&gt;Process and Runbook improvements&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I love spending the time to understand the systems I work on and the systems underlying them. I keep exploring better solutions in this continuously chaning and evolving infrastructure environment.&lt;/p&gt;
&lt;h1 id=&#34;about-this-blog&#34;&gt;About this Blog&lt;/h1&gt;
&lt;p&gt;This blog is about:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;things that I find interesting&lt;/li&gt;
&lt;li&gt;things that I am learning and would like to share&lt;/li&gt;
&lt;li&gt;things for me to refer back to&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
  </channel>
</rss>
